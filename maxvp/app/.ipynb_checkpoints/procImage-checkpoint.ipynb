{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import cv2\n",
    "# https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/textdetection.py\n",
    "#print('\\ntextdetection.py')\n",
    "#print('       A demo script of the Extremal Region Filter algorithm described in:')\n",
    "#print('       Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012\\n')\n",
    "#path_to_image_to_be_processed = '/home/pboord/Downloads/yelp/waitrose.jpg'\n",
    "#pathname = os.path.dirname(sys.argv[0])\n",
    "pathname = '/home/pboord/flask/maxvp/app/static'\n",
    "img      = cv2.imread(pathname+'/warped.jpg')\n",
    "# for visualization\n",
    "vis      = img.copy()\n",
    "allBoxes = img.copy()\n",
    "consolidatedBoxes = img.copy()\n",
    "#print cv2.__version__\n",
    "# Extract channels to be processed individually\n",
    "channels = cv2.text.computeNMChannels(img)\n",
    "# Append negative channels to detect ER- (bright regions over dark background)\n",
    "cn = len(channels)-1\n",
    "for c in range(0,cn):\n",
    "  channels.append((255-channels[c]))\n",
    "# Apply the default cascade classifier to each independent channel (could be done in parallel)\n",
    "#print(\"Extracting Class Specific Extremal Regions from \"+str(len(channels))+\" channels ...\")\n",
    "#print(\"    (...) this may take a while (...)\")\n",
    "def overlap(b1, b2):\n",
    "    return (b1[0] <= b2[0]+b2[2]) and (b1[0]+b1[2] >= b2[0]) and (b1[1] <= b2[1]+b2[3]) and (b1[1]+b1[3] >= b2[1])\n",
    "def bigrect(b1, b2):\n",
    "    b0 = b1\n",
    "    b0[0]=min(b1[0],b2[0])\n",
    "    b0[1]=min(b1[1],b2[1])\n",
    "    b0[2]=max(b1[0]+b1[2],b2[0]+b2[2]) - b0[0]\n",
    "    b0[3]=max(b1[1]+b1[3],b2[1]+b2[3]) - b0[1]\n",
    "    return b0\n",
    "def lbwh2lbrt(b):\n",
    "    b0=b\n",
    "    b0[0]=b[0]\n",
    "    b0[1]=b[1]\n",
    "    b0[2]=b[0]+b[2]\n",
    "    b0[3]=b[1]+b[3]\n",
    "    return b0\n",
    "b = []\n",
    "for channel in channels:\n",
    "\n",
    "  erc1 = cv2.text.loadClassifierNM1(pathname+'/trained_classifierNM1.xml')\n",
    "  er1 = cv2.text.createERFilterNM1(erc1,16,0.00015,0.13,0.2,True,0.1)\n",
    "\n",
    "  erc2 = cv2.text.loadClassifierNM2(pathname+'/trained_classifierNM2.xml')\n",
    "  er2 = cv2.text.createERFilterNM2(erc2,0.5)\n",
    "    # detectRegions: function in MSER class:\n",
    "    # http://docs.opencv.org/3.0.0/d3/d28/classcv_1_1MSER.html\n",
    "    # https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions\n",
    "  regions = cv2.text.detectRegions(channel,er1,er2)\n",
    "  #print regions\n",
    "    # erGrouping:\n",
    "    # Find groups of Extremal Regions that are organized as text blocks\n",
    "  rects = cv2.text.erGrouping(img,channel,[r.tolist() for r in regions])\n",
    "  #rects = cv2.text.erGrouping(img,gray,[x.tolist() for x in regions], cv2.text.ERGROUPING_ORIENTATION_ANY,'../../GSoC2014/opencv_contrib/modules/text/samples/trained_classifier_erGrouping.xml',0.5)\n",
    "  #print rects\n",
    "  #Visualization\n",
    "  for r in range(0,np.shape(rects)[0]):\n",
    "    b.append(rects[r])\n",
    "    rect = rects[r]\n",
    "    cv2.rectangle(allBoxes, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)\n",
    "    cv2.rectangle(allBoxes, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)\n",
    "cv2.imwrite(pathname+'/warped_allBoxes.jpg',allBoxes)\n",
    "# consolidate overlapping rectangles\n",
    "c = b\n",
    "h=0\n",
    "while h < len(c):\n",
    "    g=len(c) - 1\n",
    "    while g > h:\n",
    "        if overlap(c[g],c[h]):\n",
    "            c[g] = bigrect(c[g],c[h])\n",
    "            c = np.delete(c,h,axis=0)\n",
    "        g -= 1\n",
    "    h += 1\n",
    "h=0\n",
    "while h < len(c):\n",
    "    g=len(c) - 1\n",
    "    while g > h:\n",
    "        if overlap(c[g],c[h]):\n",
    "            c[g] = bigrect(c[g],c[h])\n",
    "            c = np.delete(c,h,axis=0)\n",
    "        g -= 1\n",
    "    h += 1\n",
    "for r in range(0,np.shape(c)[0]):\n",
    "    rect = c[r]\n",
    "    cv2.rectangle(consolidatedBoxes, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)\n",
    "    cv2.rectangle(consolidatedBoxes, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)\n",
    "cv2.imwrite(pathname+'/warped_consolidatedBoxes.jpg',consolidatedBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0, 276, 634, 155], dtype=int32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-35c78fe81e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# center of mass (cm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrectCM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mrectCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrectCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# select textbox closest to click\n",
    "x=247\n",
    "y=133\n",
    "# # right numberplate\n",
    "# x = 658\n",
    "# y = 369\n",
    "# # back light\n",
    "# x = 533\n",
    "# y = 376\n",
    "\n",
    "# center of mass (cm)\n",
    "rectCM = np.zeros((c.shape[0],2), dtype=int)\n",
    "rectCM[:,0] = c[:,0] + c[:,2]/2\n",
    "rectCM[:,1] = c[:,1] + c[:,3]/2\n",
    "cmDiff = rectCM - np.matlib.repmat(np.array([x,y]),rectCM.shape[0],1)\n",
    "closestRect = np.argmin(np.hypot(cmDiff[:,0],cmDiff[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print rect\n",
    "rect = c[closestRect,:]\n",
    "cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)\n",
    "cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)\n",
    "cv2.imwrite(pathname+'/warped_boxed.jpg',vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imSeg = img[ rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2] ]\n",
    "cv2.imwrite(pathname+'/textbox.jpg',imSeg)\n",
    "# for i in range(0,len(c)):\n",
    "#     #Visualization\n",
    "#     cv2.imshow(\"Text detection result\", imSeg)\n",
    "#     cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use tool 'Tesseract (sh)'\n",
      "Available languages: Info in bmfCreate: Generating pixa of bitmap fonts from string, osd, eng, chi_sim, equ\n",
      "Will use lang 'Info in bmfCreate: Generating pixa of bitmap fonts from string'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "import pyocr\n",
    "import pyocr.builders\n",
    "\n",
    "tools = pyocr.get_available_tools()\n",
    "if len(tools) == 0:\n",
    "    print(\"No OCR tool found\")\n",
    "    sys.exit(1)\n",
    "# The tools are returned in the recommended order of usage\n",
    "tool = tools[0]\n",
    "print(\"Will use tool '%s'\" % (tool.get_name()))\n",
    "# Ex: Will use tool 'libtesseract'\n",
    "\n",
    "langs = tool.get_available_languages()\n",
    "print(\"Available languages: %s\" % \", \".join(langs))\n",
    "lang = langs[0]\n",
    "print(\"Will use lang '%s'\" % (lang))\n",
    "# Ex: Will use lang 'fra'\n",
    "# Note that languages are NOT sorted in any way. Please refer\n",
    "# to the system locale settings for the default language\n",
    "# to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt is 东 下 ) 孝 驯 i 心 、\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/jflesch/pyocr#image-to-text\n",
    "txt = tool.image_to_string(\n",
    "    Image.open(pathname+'/textbox.jpg'),\n",
    "    lang=\"chi_sim\",\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "print 'txt is ' + txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function image_to_string at 0x7f5c66092938>\n"
     ]
    }
   ],
   "source": [
    "print tool.image_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pboord/flask/maxvp/app/static'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4e1c \\u4e0b ) \\u5b5d \\u9a6f i \\u5fc3 \\u3001'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "东下)孝驯i心、\n"
     ]
    }
   ],
   "source": [
    "print txt.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4e1c\\u4e0b)\\u5b5d\\u9a6fi\\u5fc3\\u3001'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=Image.open(pathname+'/textbox.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "东 下 ) 孝 驯 i 心 、\n",
      "\n",
      "\n",
      "0 东\n",
      "1  \n",
      "2 下\n",
      "3  \n",
      "4 )\n",
      "5  \n",
      "6 孝\n",
      "7  \n",
      "8 驯\n",
      "9  \n",
      "10 i\n",
      "11  \n",
      "12 心\n",
      "13  \n",
      "14 、\n"
     ]
    }
   ],
   "source": [
    "from tesseract.pytesser import image_file_to_string\n",
    "image_path = pathname+'/textbox.jpg'\n",
    "text = image_file_to_string(image_path, lang='chi_sim', graceful_errors=True)\n",
    "print text\n",
    "text = text.strip()\n",
    "text = text.decode('utf-8')\n",
    "for i in range(0,len(text)):\n",
    "    print i,text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_path = pathname+'/textbox.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = image_file_to_string(image_path, lang='chi_sim', graceful_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe6\\xb2\\xb3 E02HEEJ iiounaldduuua d \\xe6\\xa0\\x87\\n\\n\\xe6\\xb7\\xbb \\xe5\\xa5\\xbd \\xe8\\xbf\\x90 \\xe7\\x82\\xb9 \\xe5\\xbf\\x83 \\xe4\\xb8\\x93 \\xe9\\x97\\xa8 \\xe5\\xba\\x97 \\xe9\\x99\\x86 \\xe5\\x8f\\xb2 \\xe5\\x8d\\xb3\\n\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe6\\xb2\\xb3 E02HEEJ iiounaldduuua d \\xe6\\xa0\\x87\\n\\n\\xe6\\xb7\\xbb \\xe5\\xa5\\xbd \\xe8\\xbf\\x90 \\xe7\\x82\\xb9 \\xe5\\xbf\\x83 \\xe4\\xb8\\x93 \\xe9\\x97\\xa8 \\xe5\\xba\\x97 \\xe9\\x99\\x86 \\xe5\\x8f\\xb2 \\xe5\\x8d\\xb3'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from normalize import preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(text)\n",
    "text = text.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 河\n",
      "1  \n",
      "2 E\n",
      "3 0\n",
      "4 2\n",
      "5 H\n",
      "6 E\n",
      "7 E\n",
      "8 J\n",
      "9  \n",
      "10 i\n",
      "11 i\n",
      "12 o\n",
      "13 u\n",
      "14 n\n",
      "15 a\n",
      "16 l\n",
      "17 d\n",
      "18 d\n",
      "19 u\n",
      "20 u\n",
      "21 u\n",
      "22 a\n",
      "23  \n",
      "24 d\n",
      "25  \n",
      "26 标\n",
      "27 \n",
      "\n",
      "28 \n",
      "\n",
      "29 添\n",
      "30  \n",
      "31 好\n",
      "32  \n",
      "33 运\n",
      "34  \n",
      "35 点\n",
      "36  \n",
      "37 心\n",
      "38  \n",
      "39 专\n",
      "40  \n",
      "41 门\n",
      "42  \n",
      "43 店\n",
      "44  \n",
      "45 陆\n",
      "46  \n",
      "47 史\n",
      "48  \n",
      "49 即\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(text)):\n",
    "    print i,text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(text)):\n",
    "    print i,text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model.dict_entry import Dict_Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from translate import search_dish_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=open(pathname+'/textbox.jpg', 'rb').read().encode('base64').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locText ='Sham Shui Po, Hong Kong, HK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sham%20Shui%20Po%2C%20Hong%20Kong%2C%20HK'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib2\n",
    "urllib2.quote('Sham Shui Po, Hong Kong, HK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use tool 'Tesseract (sh)'\n",
      "Available languages: Info in bmfCreate: Generating pixa of bitmap fonts from string, osd, eng, chi_sim, equ\n",
      "Will use lang 'Info in bmfCreate: Generating pixa of bitmap fonts from string'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "import pyocr\n",
    "import pyocr.builders\n",
    "\n",
    "tools = pyocr.get_available_tools()\n",
    "if len(tools) == 0:\n",
    "    print(\"No OCR tool found\")\n",
    "    sys.exit(1)\n",
    "# The tools are returned in the recommended order of usage\n",
    "tool = tools[0]\n",
    "print(\"Will use tool '%s'\" % (tool.get_name()))\n",
    "# Ex: Will use tool 'libtesseract'\n",
    "\n",
    "langs = tool.get_available_languages()\n",
    "print(\"Available languages: %s\" % \", \".join(langs))\n",
    "lang = langs[0]\n",
    "print(\"Will use lang '%s'\" % (lang))\n",
    "# Ex: Will use lang 'fra'\n",
    "# Note that languages are NOT sorted in any way. Please refer\n",
    "# to the system locale settings for the default language\n",
    "# to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u''"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = tool.image_to_string(\n",
    "    Image.open(pathname+'/textbox.jpg'),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt = tool.image_to_string(\n",
    "    Image.fromarray(imSeg),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_boxes = tool.image_to_string(\n",
    "    Image.open(pathname+'/textbox.jpg'),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.WordBoxBuilder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[method for method in dir(word_boxes) if callable(getattr(word_boxes, method))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tesseract textbox.jpg out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "client = vision.Client()\n",
    "with open('./im_1.jpg', 'rb') as image_file:\n",
    "    image = client.image(content=image_file.read())\n",
    "    texts = image.detect_text()\n",
    "    texts[0].locale\n",
    "    texts[0].description\n",
    "    texts[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('digits.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Now we split the image to 5000 cells, each 20x20 size\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    "\n",
    "# Make it into a Numpy array. It size will be (50,100,20,20)\n",
    "x = np.array(cells)\n",
    "\n",
    "# Now we prepare train_data and test_data.\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "\n",
    "# Create labels for train and test data\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k,250)[:,np.newaxis]\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "# Initiate kNN, train the data, then test it with test data for k=1\n",
    "knn = cv2.KNearest()\n",
    "knn.train(train,train_labels)\n",
    "ret,result,neighbours,dist = knn.find_nearest(test,k=5)\n",
    "\n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=\"duck\"\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
